{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header: ['Source Language', 'Target Language']\n",
      "First 5 rows:\n",
      "                                      Source Language  \\\n",
      "0                              Go in search of love.   \n",
      "1                         That is almost proverbial.   \n",
      "2  Couple of that question for example s if your ...   \n",
      "3                              What has do you then?   \n",
      "4  The curtains near and guards to someone contra...   \n",
      "\n",
      "                           Target Language  \n",
      "0  Hoi Billy, wil je nog wat trucjes doen?  \n",
      "1                             Ik kan niet.  \n",
      "2                            Ik moet gaan.  \n",
      "3                            Kom, nog één.  \n",
      "4     Ik zal zaterdag op stap gaan met je.  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the .txt files for both languages\n",
    "source_file = \"/Users/ursamatjasec/Desktop/UNI/Software engineering/en-nl/OpenSubtitles.en-nl.en\"\n",
    "target_file = \"/Users/ursamatjasec/Desktop/UNI/Software engineering/nl.txt\"\n",
    "\n",
    "# Read each file into a list of sentences\n",
    "with open(source_file, 'r', encoding='utf-8') as f:\n",
    "    source_sentences = f.readlines()\n",
    "\n",
    "with open(target_file, 'r', encoding='utf-8') as f:\n",
    "    target_sentences = f.readlines()\n",
    "\n",
    "# Strip whitespace\n",
    "source_sentences = [line.strip() for line in source_sentences]\n",
    "target_sentences = [line.strip() for line in target_sentences]\n",
    "\n",
    "# Ensure both lists are the same length by truncating the longer one\n",
    "min_length = min(len(source_sentences), len(target_sentences))\n",
    "source_sentences = source_sentences[:min_length]\n",
    "target_sentences = target_sentences[:min_length]\n",
    "\n",
    "# Create a DataFrame with both languages\n",
    "df = pd.DataFrame({\n",
    "    'Source Language': source_sentences,\n",
    "    'Target Language': target_sentences\n",
    "})\n",
    "\n",
    "# Display the header of the DataFrame\n",
    "print(\"Header:\", df.columns.tolist())\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "print(\"First 5 rows:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume of Data - Number of Sentences: 299879, Number of Languages: 2\n"
     ]
    }
   ],
   "source": [
    "# Check volume by displaying the number of rows and columns\n",
    "num_rows, num_columns = df.shape\n",
    "print(f\"Volume of Data - Number of Sentences: {num_rows}, Number of Languages: {num_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average difference in sentence length: 0.0384555103891903 characters\n"
     ]
    }
   ],
   "source": [
    "# Check if both 'Source Language' and 'Target Language' columns exist\n",
    "if 'Source Language' in df.columns and 'Target Language' in df.columns:\n",
    "    # Calculate sentence lengths (number of characters or words)\n",
    "    df['source_length'] = df['Source Language'].apply(len)  # Using character length\n",
    "    df['target_length'] = df['Target Language'].apply(len)\n",
    "    \n",
    "    # Calculate the difference in length between source and target sentences\n",
    "    df['length_diff'] = df['source_length'] - df['target_length']\n",
    "    \n",
    "    # Calculate average difference in length\n",
    "    avg_length_diff = df['length_diff'].mean()\n",
    "    print(f\"Average difference in sentence length: {avg_length_diff} characters\")\n",
    "else:\n",
    "    print(\"Source or Target language column not found for analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variety of Data - Data Types of Features:\n",
      "Source Language    object\n",
      "Target Language    object\n",
      "source_length       int64\n",
      "target_length       int64\n",
      "length_diff         int64\n",
      "dtype: object\n",
      "Number of Categorical Features: 2, Number of Numerical Features: 3\n"
     ]
    }
   ],
   "source": [
    "# Check the data types of each column to analyze variety\n",
    "print(\"Variety of Data - Data Types of Features:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Count categorical and numerical columns\n",
    "num_categorical = df.select_dtypes(include=['object']).shape[1]  # Text-based data\n",
    "num_numerical = df.select_dtypes(include=['int64', 'float64']).shape[1]  # Numerical data (e.g., sentence lengths)\n",
    "print(f\"Number of Categorical Features: {num_categorical}, Number of Numerical Features: {num_numerical}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics of Numerical Features:\n",
      "       source_length  target_length    length_diff\n",
      "count  299879.000000  299879.000000  299879.000000\n",
      "mean       29.791696      29.753240       0.038456\n",
      "std        24.917848      23.929489      34.625893\n",
      "min         1.000000       0.000000    -762.000000\n",
      "25%        14.000000      14.000000     -16.000000\n",
      "50%        24.000000      24.000000       0.000000\n",
      "75%        38.000000      38.000000      16.000000\n",
      "max      1218.000000     773.000000    1176.000000\n",
      "Variety Analysis - Unique Values in Categorical Features:\n",
      "Source Language    242468\n",
      "Target Language    213374\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the summary statistics of numerical columns (e.g., sentence lengths, length differences)\n",
    "summary_statistics = df.describe()\n",
    "print(\"Summary Statistics of Numerical Features:\")\n",
    "print(summary_statistics)\n",
    "\n",
    "# Check the unique values in categorical columns (source and target sentences)\n",
    "unique_values = df.select_dtypes(include=['object']).nunique()\n",
    "print(\"Variety Analysis - Unique Values in Categorical Features:\")\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veracity Analysis - Missing Values in Each Feature:\n",
      "Source Language    0\n",
      "Target Language    0\n",
      "source_length      0\n",
      "target_length      0\n",
      "length_diff        0\n",
      "dtype: int64\n",
      "Number of Duplicated Rows: 196\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the dataset\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Veracity Analysis - Missing Values in Each Feature:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Check for duplicated rows\n",
    "num_duplicates = df.duplicated().sum()\n",
    "print(f\"Number of Duplicated Rows: {num_duplicates}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
